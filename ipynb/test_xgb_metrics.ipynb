{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named testing",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-20ce73c341c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named testing"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import testing as tm\n",
    "import numpy as np\n",
    "import unittest\n",
    "\n",
    "rng = np.random.RandomState(1337)\n",
    "\n",
    "\n",
    "class TestEvalMetrics(unittest.TestCase):\n",
    "    xgb_params_01 = {\n",
    "        'silent': 1,\n",
    "        'nthread': 1,\n",
    "        'eval_metric': 'error'\n",
    "    }\n",
    "\n",
    "    xgb_params_02 = {\n",
    "        'silent': 1,\n",
    "        'nthread': 1,\n",
    "        'eval_metric': ['error']\n",
    "    }\n",
    "\n",
    "    xgb_params_03 = {\n",
    "        'silent': 1,\n",
    "        'nthread': 1,\n",
    "        'eval_metric': ['rmse', 'error']\n",
    "    }\n",
    "\n",
    "    xgb_params_04 = {\n",
    "        'silent': 1,\n",
    "        'nthread': 1,\n",
    "        'eval_metric': ['error', 'rmse']\n",
    "    }\n",
    "\n",
    "    def evalerror_01(self, preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        return 'error', float(sum(labels != (preds > 0.0))) / len(labels)\n",
    "\n",
    "    def evalerror_02(self, preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        return [('error', float(sum(labels != (preds > 0.0))) / len(labels))]\n",
    "\n",
    "    def evalerror_03(self, preds, dtrain):\n",
    "        tm._skip_if_no_sklearn()\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "\n",
    "        labels = dtrain.get_label()\n",
    "        return [('rmse', mean_squared_error(labels, preds)),\n",
    "                ('error', float(sum(labels != (preds > 0.0))) / len(labels))]\n",
    "\n",
    "    def evalerror_04(self, preds, dtrain):\n",
    "        tm._skip_if_no_sklearn()\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "\n",
    "        labels = dtrain.get_label()\n",
    "        return [('error', float(sum(labels != (preds > 0.0))) / len(labels)),\n",
    "                ('rmse', mean_squared_error(labels, preds))]\n",
    "\n",
    "    def test_eval_metrics(self):\n",
    "        tm._skip_if_no_sklearn()\n",
    "        from sklearn.cross_validation import train_test_split\n",
    "        from sklearn.datasets import load_digits\n",
    "\n",
    "        digits = load_digits(2)\n",
    "        X = digits['data']\n",
    "        y = digits['target']\n",
    "\n",
    "        Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "        dtrain = xgb.DMatrix(Xt, label=yt)\n",
    "        dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'val')]\n",
    "\n",
    "        gbdt_01 = xgb.train(self.xgb_params_01, dtrain, num_boost_round=10)\n",
    "        gbdt_02 = xgb.train(self.xgb_params_02, dtrain, num_boost_round=10)\n",
    "        gbdt_03 = xgb.train(self.xgb_params_03, dtrain, num_boost_round=10)\n",
    "        assert gbdt_01.predict(dvalid)[0] == gbdt_02.predict(dvalid)[0]\n",
    "        assert gbdt_01.predict(dvalid)[0] == gbdt_03.predict(dvalid)[0]\n",
    "\n",
    "        gbdt_01 = xgb.train(self.xgb_params_01, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2)\n",
    "        gbdt_02 = xgb.train(self.xgb_params_02, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2)\n",
    "        gbdt_03 = xgb.train(self.xgb_params_03, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2)\n",
    "        gbdt_04 = xgb.train(self.xgb_params_04, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2)\n",
    "        assert gbdt_01.predict(dvalid)[0] == gbdt_02.predict(dvalid)[0]\n",
    "        assert gbdt_01.predict(dvalid)[0] == gbdt_03.predict(dvalid)[0]\n",
    "        assert gbdt_03.predict(dvalid)[0] != gbdt_04.predict(dvalid)[0]\n",
    "\n",
    "        gbdt_01 = xgb.train(self.xgb_params_01, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2, feval=self.evalerror_01)\n",
    "        gbdt_02 = xgb.train(self.xgb_params_02, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2, feval=self.evalerror_02)\n",
    "        gbdt_03 = xgb.train(self.xgb_params_03, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2, feval=self.evalerror_03)\n",
    "        gbdt_04 = xgb.train(self.xgb_params_04, dtrain, 10, watchlist,\n",
    "                            early_stopping_rounds=2, feval=self.evalerror_04)\n",
    "        assert gbdt_01.predict(dvalid)[0] == gbdt_02.predict(dvalid)[0]\n",
    "        assert gbdt_01.predict(dvalid)[0] == gbdt_03.predict(dvalid)[0]\n",
    "        assert gbdt_03.predict(dvalid)[0] != gbdt_04.predict(dvalid)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-6532122e45c6>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-6532122e45c6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install unittest\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}